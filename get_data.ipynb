{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from utils import get_predictions\n",
    "import torch.nn.functional as F\n",
    "from dataset import get_data,get_data2\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from sklearn import metrics\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dataset import get_data\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds, test_ids = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=1024)\n",
    "val_loader = DataLoader(val_ds, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "\n",
    "\n",
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.net(x)).view(-1)\n",
    "\n",
    "\n",
    "model = NN(input_size=200)\n",
    "optimizer = optim.Adam(model.parameters(), lr=3e-4, weight_decay= 1e-4)\n",
    "loss_fn = nn.BCELoss()\n",
    "\n",
    "\n",
    "#x, y = next(iter(train_loader))\n",
    "#print(x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.5256196675870406\n",
      "VALIDATION ROC: 0.7934739468686858\n",
      "VALIDATION ROC: 0.8389242673676187\n",
      "VALIDATION ROC: 0.849962244291963\n",
      "VALIDATION ROC: 0.8523371012460422\n",
      "VALIDATION ROC: 0.8529505313635765\n",
      "VALIDATION ROC: 0.8534267183434351\n",
      "VALIDATION ROC: 0.8534896433624757\n",
      "VALIDATION ROC: 0.8535260971015036\n",
      "VALIDATION ROC: 0.8536874430362436\n",
      "VALIDATION ROC: 0.8539320724941917\n",
      "VALIDATION ROC: 0.8539490384948418\n",
      "VALIDATION ROC: 0.8540647841666971\n",
      "VALIDATION ROC: 0.8541401994502278\n",
      "VALIDATION ROC: 0.8542379272363585\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    \n",
    "    proba, true = get_predictions(val_loader,model) \n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, proba)}\")\n",
    "    for batch_idx, (data,targets) in enumerate(train_loader) :\n",
    "       \n",
    "        \n",
    "         \n",
    "        \n",
    "        scores = model(data)\n",
    "        #print(scores.shape)\n",
    "        \n",
    "        loss = loss_fn(scores,targets)\n",
    "        #print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size,hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        \n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(1,hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size*hidden_dim,1)\n",
    "        \n",
    "        #-------------------------------------------\n",
    "        \n",
    "        \n",
    "        \"\"\"\"self.net = nn.Sequential(\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, 50),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(50, 1)\n",
    "        )\"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        Batch_size = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        # le shape actuel du shape est : (Batch_size,200)\n",
    "        x = x.view(-1,1)\n",
    "        x = F.relu(self.fc1(x)).reshape(Batch_size,-1)\n",
    "        # Batch_size,200*hidden_dim\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n",
    "        # maintenant on aura Batch_size*200,1\n",
    "        #return torch.sigmoid(self.net(x)).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = NN(input_size=200,hidden_dim=16)\n",
    "optimizer = optim.Adam(model2.parameters(), lr=3e-4, weight_decay= 1e-4)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.4459659280910186\n",
      "VALIDATION ROC: 0.8008896321497987\n",
      "VALIDATION ROC: 0.8441723553679619\n",
      "VALIDATION ROC: 0.8517911241296556\n",
      "VALIDATION ROC: 0.8581167673796699\n",
      "VALIDATION ROC: 0.8637933522590912\n",
      "VALIDATION ROC: 0.8684279404806364\n",
      "VALIDATION ROC: 0.8723297305271065\n",
      "VALIDATION ROC: 0.8750814444658598\n",
      "VALIDATION ROC: 0.8770950311429037\n",
      "VALIDATION ROC: 0.8787539583967889\n",
      "VALIDATION ROC: 0.8798535266056288\n",
      "VALIDATION ROC: 0.8808614519396774\n",
      "VALIDATION ROC: 0.8816228460632929\n",
      "VALIDATION ROC: 0.8822488953186545\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    \n",
    "    proba, true = get_predictions(val_loader,model2) \n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, proba)}\")\n",
    "    for batch_idx, (data,targets) in enumerate(train_loader) :\n",
    "       \n",
    "        \n",
    "         \n",
    "        \n",
    "        scores = model2(data)\n",
    "        #print(scores.shape)\n",
    "        \n",
    "        loss = loss_fn(scores,targets)\n",
    "        #print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 201)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [f'var_{i}' for i in range(200)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:06<00:00, 32.83it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(col_names):\n",
    "    count = test[col].value_counts()\n",
    "    uniques = count.index[count == 1]\n",
    "    test[col+\"_u\"] = test[col].isin(uniques)\n",
    "test[\"has_unique\"] = test[[col+'_u' for col in col_names]].any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3          True\n",
       "4         False\n",
       "          ...  \n",
       "199995     True\n",
       "199996     True\n",
       "199997    False\n",
       "199998    False\n",
       "199999     True\n",
       "Name: has_unique, Length: 200000, dtype: bool"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"has_unique\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['has_unique'].sum()\n",
    "# we have 100000 real data and the rest are fake "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = test.loc[test[\"has_unique\"], [\"ID_code\"] + col_names]\n",
    "fake_test = test.loc[~test[\"has_unique\"], [\"ID_code\"] + col_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test = pd.concat([train, real_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [01:05<00:00,  3.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(col_names):\n",
    "    count = train_and_test[col].value_counts().to_dict()\n",
    "    train_and_test[col+\"_unique\"] = train_and_test[col].apply(\n",
    "        lambda x: 1 if count[x] == 1 else 0).values\n",
    "    fake_test[col+\"_unique\"] = 0 \n",
    "    #print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_unique</th>\n",
       "      <th>var_191_unique</th>\n",
       "      <th>var_192_unique</th>\n",
       "      <th>var_193_unique</th>\n",
       "      <th>var_194_unique</th>\n",
       "      <th>var_195_unique</th>\n",
       "      <th>var_196_unique</th>\n",
       "      <th>var_197_unique</th>\n",
       "      <th>var_198_unique</th>\n",
       "      <th>var_199_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199986</th>\n",
       "      <td>test_199986</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.2884</td>\n",
       "      <td>-2.8384</td>\n",
       "      <td>11.9149</td>\n",
       "      <td>6.6611</td>\n",
       "      <td>12.3112</td>\n",
       "      <td>12.9244</td>\n",
       "      <td>5.6492</td>\n",
       "      <td>16.0449</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199993</th>\n",
       "      <td>test_199993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.6764</td>\n",
       "      <td>-8.1066</td>\n",
       "      <td>7.1167</td>\n",
       "      <td>2.4138</td>\n",
       "      <td>10.3845</td>\n",
       "      <td>-11.9327</td>\n",
       "      <td>4.7563</td>\n",
       "      <td>16.0455</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>test_199995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.1678</td>\n",
       "      <td>1.0136</td>\n",
       "      <td>10.4333</td>\n",
       "      <td>6.7997</td>\n",
       "      <td>8.5974</td>\n",
       "      <td>-4.1641</td>\n",
       "      <td>4.8579</td>\n",
       "      <td>14.7625</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>test_199996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7171</td>\n",
       "      <td>-9.1462</td>\n",
       "      <td>7.3443</td>\n",
       "      <td>9.1421</td>\n",
       "      <td>12.8936</td>\n",
       "      <td>3.0191</td>\n",
       "      <td>5.6888</td>\n",
       "      <td>18.8862</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>test_199999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.4664</td>\n",
       "      <td>1.8070</td>\n",
       "      <td>10.2277</td>\n",
       "      <td>6.0654</td>\n",
       "      <td>10.0258</td>\n",
       "      <td>1.0789</td>\n",
       "      <td>4.8879</td>\n",
       "      <td>14.4892</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID_code  target    var_0   var_1    var_2   var_3    var_4  \\\n",
       "0           train_0     0.0   8.9255 -6.7863  11.9081  5.0930  11.4607   \n",
       "1           train_1     0.0  11.5006 -4.1473  13.8588  5.3890  12.3622   \n",
       "2           train_2     0.0   8.6093 -2.7457  12.0805  7.8928  10.5825   \n",
       "3           train_3     0.0  11.0604 -2.1518   8.9522  7.1957  12.5846   \n",
       "4           train_4     0.0   9.8369 -1.4834  12.8746  6.6375  12.2772   \n",
       "...             ...     ...      ...     ...      ...     ...      ...   \n",
       "199986  test_199986     NaN  19.2884 -2.8384  11.9149  6.6611  12.3112   \n",
       "199993  test_199993     NaN  14.6764 -8.1066   7.1167  2.4138  10.3845   \n",
       "199995  test_199995     NaN  13.1678  1.0136  10.4333  6.7997   8.5974   \n",
       "199996  test_199996     NaN   9.7171 -9.1462   7.3443  9.1421  12.8936   \n",
       "199999  test_199999     NaN  10.4664  1.8070  10.2277  6.0654  10.0258   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190_unique  var_191_unique  \\\n",
       "0       -9.2834  5.1187  18.6266  ...               0               0   \n",
       "1        7.0433  5.6208  16.5338  ...               0               0   \n",
       "2       -9.0837  6.9427  14.6155  ...               0               0   \n",
       "3       -1.8361  5.8428  14.9250  ...               0               0   \n",
       "4        2.4486  5.9405  19.2514  ...               0               0   \n",
       "...         ...     ...      ...  ...             ...             ...   \n",
       "199986  12.9244  5.6492  16.0449  ...               0               0   \n",
       "199993 -11.9327  4.7563  16.0455  ...               0               0   \n",
       "199995  -4.1641  4.8579  14.7625  ...               1               0   \n",
       "199996   3.0191  5.6888  18.8862  ...               1               0   \n",
       "199999   1.0789  4.8879  14.4892  ...               0               0   \n",
       "\n",
       "        var_192_unique  var_193_unique  var_194_unique  var_195_unique  \\\n",
       "0                    0               0               0               0   \n",
       "1                    0               0               0               0   \n",
       "2                    0               0               0               0   \n",
       "3                    0               0               0               0   \n",
       "4                    1               1               1               0   \n",
       "...                ...             ...             ...             ...   \n",
       "199986               0               0               0               0   \n",
       "199993               0               0               0               0   \n",
       "199995               0               0               1               0   \n",
       "199996               0               0               0               0   \n",
       "199999               0               0               0               0   \n",
       "\n",
       "        var_196_unique  var_197_unique  var_198_unique  var_199_unique  \n",
       "0                    0               0               0               0  \n",
       "1                    0               0               0               0  \n",
       "2                    0               0               0               0  \n",
       "3                    0               0               0               0  \n",
       "4                    0               0               0               0  \n",
       "...                ...             ...             ...             ...  \n",
       "199986               0               0               0               0  \n",
       "199993               0               0               0               1  \n",
       "199995               0               0               0               1  \n",
       "199996               0               0               0               1  \n",
       "199999               0               0               0               1  \n",
       "\n",
       "[300000 rows x 402 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_test = train_and_test[train_and_test[\"ID_code\"].str.contains(\"test\")].copy()\n",
    "real_test.drop([\"target\"], axis=1, inplace=True)\n",
    "train = train_and_test[train_and_test[\"ID_code\"].str.contains(\"train\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.concat([real_test, fake_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"new_shiny_train.csv\", index=False)\n",
    "test.to_csv(\"new_shiny_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190_unique</th>\n",
       "      <th>var_191_unique</th>\n",
       "      <th>var_192_unique</th>\n",
       "      <th>var_193_unique</th>\n",
       "      <th>var_194_unique</th>\n",
       "      <th>var_195_unique</th>\n",
       "      <th>var_196_unique</th>\n",
       "      <th>var_197_unique</th>\n",
       "      <th>var_198_unique</th>\n",
       "      <th>var_199_unique</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_7</td>\n",
       "      <td>17.3035</td>\n",
       "      <td>-2.4212</td>\n",
       "      <td>13.3989</td>\n",
       "      <td>8.3998</td>\n",
       "      <td>11.0777</td>\n",
       "      <td>9.6449</td>\n",
       "      <td>5.9596</td>\n",
       "      <td>17.8477</td>\n",
       "      <td>-4.8068</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_11</td>\n",
       "      <td>10.6137</td>\n",
       "      <td>-2.1898</td>\n",
       "      <td>8.9090</td>\n",
       "      <td>3.8014</td>\n",
       "      <td>13.8602</td>\n",
       "      <td>-5.9802</td>\n",
       "      <td>5.5515</td>\n",
       "      <td>15.4716</td>\n",
       "      <td>-0.1714</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_15</td>\n",
       "      <td>14.8595</td>\n",
       "      <td>-4.5378</td>\n",
       "      <td>13.6483</td>\n",
       "      <td>5.6480</td>\n",
       "      <td>9.9144</td>\n",
       "      <td>1.5190</td>\n",
       "      <td>5.0358</td>\n",
       "      <td>13.4524</td>\n",
       "      <td>-2.5419</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_16</td>\n",
       "      <td>14.1732</td>\n",
       "      <td>-5.1490</td>\n",
       "      <td>9.7591</td>\n",
       "      <td>3.7316</td>\n",
       "      <td>10.3700</td>\n",
       "      <td>-21.9202</td>\n",
       "      <td>7.7130</td>\n",
       "      <td>18.8749</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID_code    var_0   var_1    var_2   var_3    var_4    var_5   var_6  \\\n",
       "3    test_3   8.5374 -1.3222  12.0220  6.5749   8.8458   3.1744  4.9397   \n",
       "7    test_7  17.3035 -2.4212  13.3989  8.3998  11.0777   9.6449  5.9596   \n",
       "11  test_11  10.6137 -2.1898   8.9090  3.8014  13.8602  -5.9802  5.5515   \n",
       "15  test_15  14.8595 -4.5378  13.6483  5.6480   9.9144   1.5190  5.0358   \n",
       "16  test_16  14.1732 -5.1490   9.7591  3.7316  10.3700 -21.9202  7.7130   \n",
       "\n",
       "      var_7   var_8  ...  var_190_unique  var_191_unique  var_192_unique  \\\n",
       "3   20.5660  3.3755  ...               0               0               0   \n",
       "7   17.8477 -4.8068  ...               0               0               0   \n",
       "11  15.4716 -0.1714  ...               0               0               0   \n",
       "15  13.4524 -2.5419  ...               0               0               1   \n",
       "16  18.8749  0.4680  ...               0               0               0   \n",
       "\n",
       "    var_193_unique  var_194_unique  var_195_unique  var_196_unique  \\\n",
       "3                0               0               0               0   \n",
       "7                0               0               0               0   \n",
       "11               0               0               0               1   \n",
       "15               0               0               0               0   \n",
       "16               0               0               0               0   \n",
       "\n",
       "    var_197_unique  var_198_unique  var_199_unique  \n",
       "3                0               0               1  \n",
       "7                0               1               0  \n",
       "11               0               0               1  \n",
       "15               0               0               1  \n",
       "16               0               0               0  \n",
       "\n",
       "[5 rows x 401 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds, test_ids = get_data2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_ds, batch_size=1024, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=1024)\n",
    "val_loader = DataLoader(val_ds, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim):\n",
    "        super(NN, self).__init__()\n",
    "        self.bn = nn.BatchNorm1d(input_size)\n",
    "        self.fc1 = nn.Linear(2, hidden_dim)\n",
    "        self.fc2 = nn.Linear(input_size//2*hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        N = x.shape[0]\n",
    "        x = self.bn(x)\n",
    "        orig_features = x[:, :200].unsqueeze(2) # (N, 200, 1)\n",
    "        new_features = x[:, 200:].unsqueeze(2) # (N, 200, 1)\n",
    "        x = torch.cat([orig_features, new_features], dim=2) # (N, 200, 2)\n",
    "        x = F.relu(self.fc1(x)).reshape(N, -1) # (N, 200*hidden_dim)\n",
    "        return torch.sigmoid(self.fc2(x)).view(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = NN(input_size=400, hidden_dim=100)\n",
    "optimizer = optim.Adam(model3.parameters(), lr=2e-3, weight_decay=1e-4)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION ROC: 0.6884469696969696\n",
      "VALIDATION ROC: 0.9308712121212122\n",
      "VALIDATION ROC: 0.9183238636363635\n",
      "VALIDATION ROC: 0.928503787878788\n",
      "VALIDATION ROC: 0.9377367424242424\n",
      "VALIDATION ROC: 0.9386837121212122\n",
      "VALIDATION ROC: 0.9261363636363635\n",
      "VALIDATION ROC: 0.9341856060606061\n",
      "VALIDATION ROC: 0.9363162878787878\n",
      "VALIDATION ROC: 0.9308712121212122\n",
      "VALIDATION ROC: 0.9427083333333333\n",
      "VALIDATION ROC: 0.9356060606060606\n",
      "VALIDATION ROC: 0.9325284090909092\n",
      "VALIDATION ROC: 0.935842803030303\n",
      "VALIDATION ROC: 0.9382102272727272\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(15):\n",
    "    \n",
    "    proba, true = get_predictions(val_loader,model3) \n",
    "    print(f\"VALIDATION ROC: {metrics.roc_auc_score(true, proba)}\")\n",
    "    for batch_idx, (data,targets) in enumerate(train_loader) :\n",
    "       \n",
    "        \n",
    "         \n",
    "        \n",
    "        scores = model3(data)\n",
    "        #print(scores.shape)\n",
    "        \n",
    "        loss = loss_fn(scores,targets)\n",
    "        #print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_submission(model, loader, test_ids):\n",
    "    all_preds = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x,y in loader:\n",
    "            #print(x.shape)\n",
    "            x = x\n",
    "            score = model(x)\n",
    "            prediction = score.float()\n",
    "            all_preds += prediction.tolist()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"ID_code\" : test_ids.values,\n",
    "        \"target\" : np.array(all_preds)\n",
    "    })\n",
    "\n",
    "    df.to_csv(\"sub.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([1024, 400])\n",
      "torch.Size([320, 400])\n"
     ]
    }
   ],
   "source": [
    "get_submission(model3, test_loader, test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
